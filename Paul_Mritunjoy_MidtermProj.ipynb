{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install the necessary libraries\n",
    "\n",
    "#If you remove the#s and run the below cell, you will have the needed functions to use the built-in librari'#\n",
    "#%pip install apyori\n",
    "#%pip install fpgrowth\n",
    "#%pip install mlxtend\n",
    "\n",
    "\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from apyori import apriori\n",
    "from mlxtend.frequent_patterns import fpgrowth, association_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_-Oy16TMOeRM",
    "outputId": "5f13b5c0-103e-468b-eebd-58f24b9dba9f"
   },
   "outputs": [],
   "source": [
    "#The below function will give the user flexibility to select the data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def get_dataset():\n",
    "    datasets = {\n",
    "        1: 'Best Buy.csv',\n",
    "        2: 'Whole Foods.csv',\n",
    "        3: 'Nike.csv',\n",
    "        4: 'Walmart.csv',\n",
    "        5: 'Barnes & Noble.csv'\n",
    "    }\n",
    "\n",
    "    print(\"Welcome to Apriori 2.0!\")\n",
    "    print(\"User please select your store:\")\n",
    "    print(\"1. Best Buy\")\n",
    "    print(\"2. Whole Foods\")\n",
    "    print(\"3. Nike\")\n",
    "    print(\"4. Walmart\")\n",
    "    print(\"5. Barnes & Nobles\")\n",
    "\n",
    "    user = 0\n",
    "\n",
    "    #Keep asking until the user provides a valid selection\n",
    "    while user < 1 or user > 5:\n",
    "      user = int(input(\"Please enter a number between 1 and 5: \"))\n",
    "\n",
    "    #Return the selected dataset\n",
    "    return datasets[user]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W2qeJm-lOsPB",
    "outputId": "4bb83796-5766-4c8f-c888-680badd01f06"
   },
   "outputs": [],
   "source": [
    "#This will count the frequency of occurrence for each item\n",
    "def count_occurences(itemset, Transactions):\n",
    "  count = 0\n",
    "  for t in Transactions:\n",
    "    if set(itemset).issubset(set(t)):\n",
    "      count+=1\n",
    "  return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "njXPj5ZPOsRN",
    "outputId": "8b96b8f6-11dd-449d-aa95-5593eef3581d"
   },
   "outputs": [],
   "source": [
    "#This function will calculate the frequent item set\n",
    "def get_frequent(itemsets, Transactions, min_support, prev_discarded):\n",
    "  L=[]\n",
    "  supp_count = []\n",
    "  new_discarded = []\n",
    "  k = len(prev_discarded.keys())\n",
    "  for s in range(len(itemsets)):\n",
    "    discarded_before = False\n",
    "    if k>0:\n",
    "      for item in prev_discarded[k]:\n",
    "        if set(item).issubset(set(itemsets[s])):\n",
    "          discarded_before = True\n",
    "          break\n",
    "    if not discarded_before:\n",
    "      count = count_occurences(itemsets[s],Transactions)\n",
    "      if count/len(Transactions) >= min_support:\n",
    "        L.append(itemsets[s])\n",
    "        supp_count.append(count)\n",
    "      else:\n",
    "        new_discarded.append(itemsets[s])\n",
    "\n",
    "  return L,supp_count,new_discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UdGO6g8tOeT6",
    "outputId": "7946a2ee-944b-4b7b-db58-acc8464655be"
   },
   "outputs": [],
   "source": [
    "#We will join two itemsets\n",
    "def join_two_itemsets(it1,it2,order):\n",
    "  it1.sort(key = lambda x:order.index(x))\n",
    "  it2.sort(key = lambda x:order.index(x))\n",
    "  for i in range(len(it1)-1):\n",
    "    if it1[i]!=it2[i]:\n",
    "      return []\n",
    "\n",
    "  if order.index(it1[-1])<order.index(it2[-1]):\n",
    "    return it1+[it2[-1]]\n",
    "  else:\n",
    "    return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lfF6cSjFOeWk",
    "outputId": "36d27563-3eb4-4ed7-9d8b-5f66affce1db"
   },
   "outputs": [],
   "source": [
    "def join_itemsets(set_of_its, order):\n",
    "  C = []\n",
    "  for i in range(len(set_of_its)):\n",
    "    for j in range(i+1, len(set_of_its)):\n",
    "      it_out = join_two_itemsets(set_of_its[i],set_of_its[j],order)\n",
    "      if len(it_out)>0:\n",
    "        C.append(it_out)\n",
    "  return C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DdB47zkyOeY7",
    "outputId": "12e32975-5e4f-470c-fe8e-77764fc080c4"
   },
   "outputs": [],
   "source": [
    "#Befow function will calculate the combinations of different functions\n",
    "from itertools import combinations, chain,permutations\n",
    "def powerset(iterable):\n",
    "    # Generate permutations of all possible lengths\n",
    "    return list(chain.from_iterable(combinations(iterable, r) for r in range(1, len(iterable) + 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UbL6PGDiOebc",
    "outputId": "c2b6a219-88f9-4af0-9494-db37a6163bf0"
   },
   "outputs": [],
   "source": [
    "#Format the output of brute force\n",
    "def write_rules(counter,X, X_S,S,conf, supp, num_trans):\n",
    "  out_rules = \"\"\n",
    "  out_rules+=\"Rule {} \".format(counter)\n",
    "  out_rules+=\"Freq.Itemset{}\\n\".format(X)\n",
    "  out_rules+=\"Rule: {} -> {}\\n\".format(list(S),list(X_S))\n",
    "  out_rules+=\"Support Count: {}\\n\".format(supp/num_trans)\n",
    "  out_rules+=\"Confidence: {}\\n\".format(round(conf,2))\n",
    "  out_rules+=\"-\" * 30\n",
    "  out_rules+=\"\\n\"\n",
    "  return out_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WujsBBKm5HMg",
    "outputId": "912709c3-65ca-4ea7-dfd7-7e2a040327d7"
   },
   "outputs": [],
   "source": [
    "#The below function will generate the final output\n",
    "import time\n",
    "def generate_association_rules(L, Transactions, min_confidence, min_support, num_trans):\n",
    "    start_time = time.time()\n",
    "    counter = 1\n",
    "    assoc_rules_str = \"\"\n",
    "    for i in range(1, len(L)):\n",
    "        for j in range(len(L[i])):\n",
    "            S = powerset(L[i][j])\n",
    "            S.pop()\n",
    "            for z in S:\n",
    "                S = set(z)\n",
    "                X = set(L[i][j])\n",
    "                X_S = set(X - S)\n",
    "                # Support and confidence calculations\n",
    "                sup_x = count_occurences(X, Transactions)\n",
    "                sup_x_s = count_occurences(X_S, Transactions)\n",
    "                conf = sup_x / count_occurences(S, Transactions)\n",
    "                # It will check the minimum thresholds\n",
    "                if conf >= min_confidence and sup_x / num_trans >= min_support:\n",
    "                    assoc_rules_str += write_rules(counter, X, X_S, S, conf, sup_x , num_trans)\n",
    "                    counter += 1\n",
    "    end_time = time.time()\n",
    "    execution_time = end_time - start_time\n",
    "    assoc_rules_str += f\"\\nExecution Time: {round(execution_time, 4)} seconds\\n\"\n",
    "    return assoc_rules_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hNN39rdOedm",
    "outputId": "cd4a5716-2265-45b5-9ef9-9cfff56e272e"
   },
   "outputs": [],
   "source": [
    "#The below code will format the output for the fpgrwoth\n",
    "def format_frequent_itemsets(frequent_itemsets):\n",
    "    print(\"\\nFrequent Itemsets:\")\n",
    "    for itemset in frequent_itemsets.iterrows():\n",
    "        items = list(itemset['itemsets'])\n",
    "        support = round(itemset['support'], 2)\n",
    "        print(f\"Itemset: {items}, Support: {support}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ohvpJi68OegF",
    "outputId": "261a84bd-5a4d-48de-d255-96665d62a15a"
   },
   "outputs": [],
   "source": [
    "#The below function will format the rules for the fpgrowth tree\n",
    "def format_rules(rules):\n",
    "    for rule_no, rule in enumerate(rules.iterrows(), start=1):\n",
    "        base_items = list(rule[1]['antecedents'])\n",
    "        add_items = list(rule[1]['consequents'])\n",
    "        support = round(rule[1]['support'], 2)\n",
    "        confidence = round(rule[1]['confidence'], 2)\n",
    "\n",
    "        print(f\"Rule {rule_no}: {base_items} -> {add_items}\")\n",
    "        print(f\"Support Count: {support}\")\n",
    "        print(f\"Confidence: {confidence}\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FfWjosPtoEMb",
    "outputId": "8d116506-4f22-488b-9973-cd60c78055d1"
   },
   "outputs": [],
   "source": [
    "\n",
    "def run_apriori(transactions, min_support, min_confidence):\n",
    "    import time\n",
    "    start_time = time.time()\n",
    "    rules = apriori(transactions, min_support=min_support, min_confidence=min_confidence)\n",
    "    rules = list(rules)\n",
    "    apriori_time = time.time() - start_time\n",
    "    print(\"\\nGenerated Association Rules (Apriori):\")\n",
    "    rule_no = 1\n",
    "    for rule in rules:\n",
    "        for ordered_stat in rule.ordered_statistics:\n",
    "            LHS = list(ordered_stat.items_base)\n",
    "            RHS = list(ordered_stat.items_add)\n",
    "            support = rule.support\n",
    "            confidence = ordered_stat.confidence\n",
    "            if len(LHS) > 0:\n",
    "                print(f\"Rule {rule_no}: {LHS} -> {RHS}\")\n",
    "                print(f\"Support Count: {round(support, 2)}\")\n",
    "                print(f\"Confidence: {round(confidence, 2)}\")\n",
    "                print(\"-\" * 30)\n",
    "                rule_no += 1\n",
    "    return apriori_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dWe7Q688yro2",
    "outputId": "e5f3ec9c-5d04-40d7-8f37-c89239e48a7d"
   },
   "outputs": [],
   "source": [
    "#The below function will calculate the FP Growth tree based on the built in function\n",
    "#I have added some check points as I was facing some errors\n",
    "def run_fp_growth(transactions, min_support, min_confidence):\n",
    "    import time\n",
    "    from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
    "    import pandas as pd\n",
    "    transactions = [list(set(transaction)) for transaction in transactions]\n",
    "    onehot = pd.get_dummies(pd.DataFrame(transactions).stack()).groupby(level=0).sum()\n",
    "    if onehot.empty:\n",
    "        return\n",
    "    start_time = time.time()\n",
    "    frequent_itemsets = fpgrowth(onehot, min_support=min_support, use_colnames=True)\n",
    "    if frequent_itemsets.empty:\n",
    "        return\n",
    "    rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
    "    if rules.empty:\n",
    "        return\n",
    "\n",
    "    fp_growth_time = time.time() - start_time\n",
    "\n",
    "    print(\"\\nGenerated Association Rules (FP-Growth):\")\n",
    "    format_rules(rules)\n",
    "\n",
    "    return fp_growth_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyNvOAZHOeoP",
    "outputId": "ed415ca4-5cec-4df1-f361-6a018236ffca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Apriori 2.0!\n",
      "User please select your store:\n",
      "1. Best Buy\n",
      "2. Whole Foods\n",
      "3. Nike\n",
      "4. Walmart\n",
      "5. Barnes & Nobles\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please enter a number between 1 and 5:  45\n",
      "Please enter a number between 1 and 5:  90\n",
      "Please enter a number between 1 and 5:  5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You have selected dataset located in Barnes & Noble.csv\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Please give the minimum support in % (Value from 1 to 100):  45\n",
      "Please give the Minimum confidence in % (Value from 1 to 100):  90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For brute force Apriori output\n",
      "\n",
      "Rule 1 Freq.Itemset{'To Kill a Mockingbird', '1984'}\n",
      "Rule: ['1984'] -> ['To Kill a Mockingbird']\n",
      "Support Count: 0.5\n",
      "Confidence: 1.0\n",
      "------------------------------\n",
      "Rule 2 Freq.Itemset{'To Kill a Mockingbird', '1984'}\n",
      "Rule: ['To Kill a Mockingbird'] -> ['1984']\n",
      "Support Count: 0.5\n",
      "Confidence: 1.0\n",
      "------------------------------\n",
      "\n",
      "Execution Time: 0.0002 seconds\n",
      "\n",
      "\n",
      "Running Apriori Algorithm...\n",
      "\n",
      "Generated Association Rules (Apriori):\n",
      "Rule 1: ['1984'] -> ['To Kill a Mockingbird']\n",
      "Support Count: 0.5\n",
      "Confidence: 1.0\n",
      "------------------------------\n",
      "Rule 2: ['To Kill a Mockingbird'] -> ['1984']\n",
      "Support Count: 0.5\n",
      "Confidence: 1.0\n",
      "------------------------------\n",
      "\n",
      "Apriori Algorithm Runtime: 0.0003 seconds\n",
      "\n",
      "Running FP-Growth Algorithm...\n",
      "\n",
      "Generated Association Rules (FP-Growth):\n",
      "Rule 1: ['To Kill a Mockingbird'] -> ['1984']\n",
      "Support Count: 0.5\n",
      "Confidence: 1.0\n",
      "------------------------------\n",
      "Rule 2: ['1984'] -> ['To Kill a Mockingbird']\n",
      "Support Count: 0.5\n",
      "Confidence: 1.0\n",
      "------------------------------\n",
      "\n",
      "FP-Growth Algorithm Runtime: 0.0032 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/mlxtend/frequent_patterns/fpcommon.py:109: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    import time\n",
    "    selected_dataset = get_dataset()\n",
    "    print(f\"You have selected dataset located in {selected_dataset}\")\n",
    "\n",
    "    data = pd.read_csv(selected_dataset)\n",
    "\n",
    "    #Convert the data set into sets\n",
    "    Transactions = []\n",
    "    for i in data['Items']:\n",
    "        Transaction = i.split(\", \")\n",
    "        Transactions.append(Transaction)\n",
    "\n",
    "    # Define minimum support and confidence\n",
    "    # Restriction has been imposed for user input\n",
    "    min_support = 0\n",
    "\n",
    "    while min_support < 1 or min_support > 100:\n",
    "\n",
    "       min_support = float(input(\"Please give the minimum support in % (Value from 1 to 100): \"))\n",
    "\n",
    "    min_support = min_support / 100\n",
    "\n",
    "\n",
    "    min_confidence = 0\n",
    "\n",
    "    while min_confidence < 1 or min_confidence > 100:\n",
    "\n",
    "      min_confidence = float(input(\"Please give the Minimum confidence in % (Value from 1 to 100): \"))\n",
    "\n",
    "    min_confidence = min_confidence / 100\n",
    "\n",
    "\n",
    "\n",
    "    #find the unique items in the set\n",
    "\n",
    "    unique_items = set(item for sublist in Transactions for item in sublist)\n",
    "    order = list(unique_items)\n",
    "\n",
    "\n",
    "    #We will define two empty dictionaries for Candidate and frequent itemsets\n",
    "    #We will take each unique item from the list and convert them into their own list\n",
    "    C = {}\n",
    "    L = {}\n",
    "    supp_count_L = {}\n",
    "    item_size = 1\n",
    "    C.update({item_size:[[f] for f in order]})\n",
    "\n",
    "    discarded = {item_size:[]}\n",
    "    f,sup,new_discarded = get_frequent(C[item_size],Transactions,min_support, discarded)\n",
    "\n",
    "    discarded.update({item_size:new_discarded})\n",
    "    L.update({item_size:f})\n",
    "    supp_count_L.update({item_size:sup})\n",
    "    k = item_size+1\n",
    "\n",
    "    convergence = False\n",
    "    while not convergence:\n",
    "      C.update({k:join_itemsets(L[k-1],order)})\n",
    "\n",
    "      f,sup, new_discarded = get_frequent(C[k],Transactions,min_support,discarded)\n",
    "      discarded.update({k:new_discarded})\n",
    "      L.update({k:f})\n",
    "      supp_count_L.update({k:sup})\n",
    "      if len(L[k])==0:\n",
    "        convergence = True\n",
    "\n",
    "      k+=1\n",
    "    num_trans =len(Transactions)\n",
    "\n",
    "    #We will calculate the frequent item set out of total itemset\n",
    "    print(\"For brute force Apriori output\\n\")\n",
    "\n",
    "    print(generate_association_rules(L, Transactions, min_confidence, min_support, num_trans))\n",
    "\n",
    "\n",
    "    print(\"\\nRunning Apriori Algorithm...\")\n",
    "    apriori_time = run_apriori(Transactions, min_support, min_confidence)\n",
    "    print(f\"\\nApriori Algorithm Runtime: {apriori_time:.4f} seconds\")\n",
    "\n",
    "\n",
    "    print(\"\\nRunning FP-Growth Algorithm...\")\n",
    "    fp_growth_time = run_fp_growth(Transactions, min_support, min_confidence)\n",
    "\n",
    "    if fp_growth_time is not None:\n",
    "        print(f\"\\nFP-Growth Algorithm Runtime: {fp_growth_time:.4f} seconds\")\n",
    "    else:\n",
    "        print(\"\\nFP-Growth did not produce any results.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
